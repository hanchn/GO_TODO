# ç¬¬11ç« ï¼šæ€§èƒ½ä¼˜åŒ–

æœ¬ç« å°†æ·±å…¥æ¢è®¨Goå­¦ç”Ÿç®¡ç†ç³»ç»Ÿçš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬ä»£ç ä¼˜åŒ–ã€æ•°æ®åº“ä¼˜åŒ–ã€ç¼“å­˜ç­–ç•¥ã€å¹¶å‘ä¼˜åŒ–å’Œç³»ç»Ÿè°ƒä¼˜ã€‚

## 11.1 æ€§èƒ½åˆ†æåŸºç¡€

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ç±»å‹ | å…³é”®æŒ‡æ ‡ | ç›®æ ‡å€¼ | ç›‘æ§æ–¹æ³• |
|---------|---------|--------|----------|
| ğŸš€ **å“åº”æ—¶é—´** | P95å»¶è¿Ÿ | < 200ms | APMç›‘æ§ |
| ğŸ“Š **ååé‡** | QPS | > 1000 | å‹åŠ›æµ‹è¯• |
| ğŸ’¾ **å†…å­˜ä½¿ç”¨** | å †å†…å­˜ | < 512MB | å†…å­˜åˆ†æ |
| ğŸ”„ **CPUä½¿ç”¨** | CPUåˆ©ç”¨ç‡ | < 70% | ç³»ç»Ÿç›‘æ§ |
| ğŸ—„ï¸ **æ•°æ®åº“** | æŸ¥è¯¢æ—¶é—´ | < 50ms | æ…¢æŸ¥è¯¢æ—¥å¿— |
| ğŸŒ **ç½‘ç»œ** | å¸¦å®½ä½¿ç”¨ | < 100MB/s | ç½‘ç»œç›‘æ§ |

### æ€§èƒ½åˆ†æå·¥å…·

**æ–‡ä»¶è·¯å¾„ï¼š** `tools/profiling.go`

```

## 11.6 Goè¿è¡Œæ—¶ä¼˜åŒ–

### è¿è¡Œæ—¶å‚æ•°è°ƒä¼˜

**æ–‡ä»¶è·¯å¾„ï¼š** `optimizations/runtime.go`

```go
package optimizations

import (
	"fmt"
	"runtime"
	"runtime/debug"
	"time"
)

// RuntimeOptimizer è¿è¡Œæ—¶ä¼˜åŒ–å™¨
type RuntimeOptimizer struct {
	gcPercent    int
	maxProcs     int
	memoryLimit  int64
	gcTargetTime time.Duration
}

// NewRuntimeOptimizer åˆ›å»ºè¿è¡Œæ—¶ä¼˜åŒ–å™¨
func NewRuntimeOptimizer() *RuntimeOptimizer {
	return &RuntimeOptimizer{
		gcPercent:    100,
		maxProcs:     runtime.NumCPU(),
		memoryLimit:  0,
		gcTargetTime: 2 * time.Millisecond,
	}
}

// OptimizeForProduction ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–
func (ro *RuntimeOptimizer) OptimizeForProduction() {
	// è®¾ç½®GOMAXPROCS
	runtime.GOMAXPROCS(ro.maxProcs)
	
	// è®¾ç½®GCç›®æ ‡ç™¾åˆ†æ¯”
	debug.SetGCPercent(ro.gcPercent)
	
	// è®¾ç½®å†…å­˜é™åˆ¶ï¼ˆGo 1.19+ï¼‰
	if ro.memoryLimit > 0 {
		debug.SetMemoryLimit(ro.memoryLimit)
	}
	
	// å¯ç”¨GCè°ƒä¼˜
	go ro.dynamicGCTuning()
}

// OptimizeForDevelopment å¼€å‘ç¯å¢ƒä¼˜åŒ–
func (ro *RuntimeOptimizer) OptimizeForDevelopment() {
	// å¼€å‘ç¯å¢ƒä½¿ç”¨æ›´æ¿€è¿›çš„GC
	debug.SetGCPercent(50)
	
	// å¯ç”¨è¯¦ç»†çš„GCæ—¥å¿—
	runtime.GC()
}

// dynamicGCTuning åŠ¨æ€GCè°ƒä¼˜
func (ro *RuntimeOptimizer) dynamicGCTuning() {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()
	
	for range ticker.C {
		var m runtime.MemStats
		runtime.ReadMemStats(&m)
		
		// æ ¹æ®å†…å­˜ä½¿ç”¨æƒ…å†µè°ƒæ•´GC
		if m.HeapInuse > m.HeapSys/2 {
			// å†…å­˜ä½¿ç”¨ç‡é«˜ï¼Œå¢åŠ GCé¢‘ç‡
			debug.SetGCPercent(50)
		} else {
			// å†…å­˜ä½¿ç”¨ç‡ä½ï¼Œé™ä½GCé¢‘ç‡
			debug.SetGCPercent(200)
		}
	}
}

// GetRuntimeStats è·å–è¿è¡Œæ—¶ç»Ÿè®¡
func (ro *RuntimeOptimizer) GetRuntimeStats() map[string]interface{} {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	
	return map[string]interface{}{
		"goroutines":     runtime.NumGoroutine(),
		"heap_alloc":     m.HeapAlloc,
		"heap_sys":       m.HeapSys,
		"heap_inuse":     m.HeapInuse,
		"heap_released":  m.HeapReleased,
		"gc_runs":        m.NumGC,
		"gc_pause_total": m.PauseTotalNs,
		"gc_pause_avg":   m.PauseTotalNs / uint64(m.NumGC),
		"next_gc":        m.NextGC,
		"gc_percent":     debug.SetGCPercent(-1),
	}
}
```

## 11.7 æ€§èƒ½æµ‹è¯•

### å¹¶å‘æ€§èƒ½æµ‹è¯•

**æ–‡ä»¶è·¯å¾„ï¼š** `tests/performance_test.go`

```go
package tests

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"net/http/httptest"
	"runtime"
	"sync"
	"testing"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/stretchr/testify/assert"
)

// TestConcurrentRequests å¹¶å‘è¯·æ±‚æµ‹è¯•
func TestConcurrentRequests(t *testing.T) {
	// è®¾ç½®æµ‹è¯•å‚æ•°
	concurrency := 100
	requestsPerWorker := 10
	totalRequests := concurrency * requestsPerWorker
	
	// åˆ›å»ºæµ‹è¯•æœåŠ¡å™¨
	router := setupTestRouter()
	server := httptest.NewServer(router)
	defer server.Close()
	
	// æ€§èƒ½æŒ‡æ ‡
	var (
		successCount int64
		errorCount   int64
		totalTime    time.Duration
		mu           sync.Mutex
		wg           sync.WaitGroup
	)
	
	startTime := time.Now()
	
	// å¯åŠ¨å¹¶å‘æµ‹è¯•
	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			
			for j := 0; j < requestsPerWorker; j++ {
				reqStart := time.Now()
				
				// å‘é€è¯·æ±‚
				resp, err := http.Get(server.URL + "/api/students")
				reqDuration := time.Since(reqStart)
				
				mu.Lock()
				if err != nil || resp.StatusCode != 200 {
					errorCount++
				} else {
					successCount++
				}
				totalTime += reqDuration
				mu.Unlock()
				
				if resp != nil {
					resp.Body.Close()
				}
			}
		}()
	}
	
	wg.Wait()
	elapsedTime := time.Since(startTime)
	
	// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
	qps := float64(totalRequests) / elapsedTime.Seconds()
	avgResponseTime := totalTime / time.Duration(totalRequests)
	successRate := float64(successCount) / float64(totalRequests) * 100
	
	// è¾“å‡ºç»“æœ
	t.Logf("å¹¶å‘æ€§èƒ½æµ‹è¯•ç»“æœ:")
	t.Logf("æ€»è¯·æ±‚æ•°: %d", totalRequests)
	t.Logf("å¹¶å‘æ•°: %d", concurrency)
	t.Logf("æˆåŠŸè¯·æ±‚: %d", successCount)
	t.Logf("å¤±è´¥è¯·æ±‚: %d", errorCount)
	t.Logf("æˆåŠŸç‡: %.2f%%", successRate)
	t.Logf("QPS: %.2f", qps)
	t.Logf("å¹³å‡å“åº”æ—¶é—´: %v", avgResponseTime)
	t.Logf("æ€»è€—æ—¶: %v", elapsedTime)
	
	// æ–­è¨€æ€§èƒ½è¦æ±‚
	assert.True(t, qps > 100, "QPSåº”è¯¥å¤§äº100")
	assert.True(t, avgResponseTime < 100*time.Millisecond, "å¹³å‡å“åº”æ—¶é—´åº”è¯¥å°äº100ms")
	assert.True(t, successRate > 99, "æˆåŠŸç‡åº”è¯¥å¤§äº99%")
}

// BenchmarkStudentOperations å­¦ç”Ÿæ“ä½œåŸºå‡†æµ‹è¯•
func BenchmarkStudentOperations(b *testing.B) {
	router := setupTestRouter()
	server := httptest.NewServer(router)
	defer server.Close()
	
	b.Run("CreateStudent", func(b *testing.B) {
		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			student := map[string]interface{}{
				"name":      fmt.Sprintf("Student%d", i),
				"student_id": fmt.Sprintf("S%06d", i),
				"email":     fmt.Sprintf("student%d@test.com", i),
				"phone":     "13800138000",
				"age":       20,
			}
			
			body, _ := json.Marshal(student)
			resp, err := http.Post(server.URL+"/api/students", "application/json", bytes.NewBuffer(body))
			if err != nil {
				b.Fatal(err)
			}
			resp.Body.Close()
		}
	})
	
	b.Run("GetStudents", func(b *testing.B) {
		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			resp, err := http.Get(server.URL + "/api/students")
			if err != nil {
				b.Fatal(err)
			}
			resp.Body.Close()
		}
	})
}

// BenchmarkMemoryUsage å†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•
func BenchmarkMemoryUsage(b *testing.B) {
	var m1, m2 runtime.MemStats
	
	// å¼ºåˆ¶GCå¹¶è·å–åˆå§‹å†…å­˜çŠ¶æ€
	runtime.GC()
	runtime.ReadMemStats(&m1)
	
	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		// æ¨¡æ‹Ÿå­¦ç”Ÿæ•°æ®å¤„ç†
		students := make([]Student, 1000)
		for j := range students {
			students[j] = Student{
				Name:      fmt.Sprintf("Student%d", j),
				StudentID: fmt.Sprintf("S%06d", j),
				Email:     fmt.Sprintf("student%d@test.com", j),
				Phone:     "13800138000",
				Age:       20,
			}
		}
		
		// æ¨¡æ‹Ÿæ•°æ®å¤„ç†
		processStudents(students)
	}
	b.StopTimer()
	
	// å¼ºåˆ¶GCå¹¶è·å–æœ€ç»ˆå†…å­˜çŠ¶æ€
	runtime.GC()
	runtime.ReadMemStats(&m2)
	
	// è®¡ç®—å†…å­˜åˆ†é…
	allocated := m2.TotalAlloc - m1.TotalAlloc
	allocationsPerOp := allocated / uint64(b.N)
	
	b.ReportMetric(float64(allocationsPerOp), "bytes/op")
	b.ReportMetric(float64(m2.Mallocs-m1.Mallocs)/float64(b.N), "allocs/op")
}

// processStudents å¤„ç†å­¦ç”Ÿæ•°æ®ï¼ˆæ¨¡æ‹Ÿä¸šåŠ¡é€»è¾‘ï¼‰
func processStudents(students []Student) {
	// æ¨¡æ‹Ÿæ•°æ®éªŒè¯å’Œå¤„ç†
	for i := range students {
		// éªŒè¯é‚®ç®±æ ¼å¼
		if len(students[i].Email) > 0 {
			// ç®€å•çš„é‚®ç®±éªŒè¯
			_ = students[i].Email
		}
		
		// éªŒè¯å¹´é¾„èŒƒå›´
		if students[i].Age < 16 || students[i].Age > 100 {
			students[i].Age = 20 // é»˜è®¤å¹´é¾„
		}
	}
}
```

## 11.8 æ€»ç»“

### æ ¸å¿ƒç‰¹æ€§

1. **å†…å­˜ä¼˜åŒ–**
   - å¯¹è±¡æ± å¤ç”¨
   - é›¶æ‹·è´è½¬æ¢
   - ç´§å‡‘æ•°æ®ç»“æ„

2. **å¹¶å‘ä¼˜åŒ–**
   - Worker Poolæ¨¡å¼
   - å¹¶å‘å®‰å…¨çš„Map
   - é™æµå™¨å’Œç†”æ–­å™¨

3. **æ•°æ®åº“ä¼˜åŒ–**
   - æŸ¥è¯¢ä¼˜åŒ–
   - ç´¢å¼•ç­–ç•¥
   - è¿æ¥æ± è°ƒä¼˜

4. **ç¼“å­˜ç®¡ç†**
   - å¤šçº§ç¼“å­˜
   - ç¼“å­˜é¢„çƒ­
   - ç»Ÿè®¡ç›‘æ§

5. **ç½‘ç»œä¼˜åŒ–**
   - GZIPå‹ç¼©
   - Keep-Alive
   - ETagç¼“å­˜

6. **è¿è¡Œæ—¶ä¼˜åŒ–**
   - GCè°ƒä¼˜
   - å†…å­˜é™åˆ¶
   - åŠ¨æ€è°ƒæ•´

### æœ€ä½³å®è·µ

1. **æ€§èƒ½ç›‘æ§**
   - å»ºç«‹æ€§èƒ½åŸºçº¿
   - æŒç»­ç›‘æ§å…³é”®æŒ‡æ ‡
   - å®šæœŸæ€§èƒ½æµ‹è¯•

2. **ä¼˜åŒ–ç­–ç•¥**
   - å…ˆæµ‹é‡å†ä¼˜åŒ–
   - å…³æ³¨çƒ­ç‚¹ä»£ç 
   - å¹³è¡¡å¤æ‚åº¦å’Œæ€§èƒ½

3. **èµ„æºç®¡ç†**
   - åˆç†è®¾ç½®è¿æ¥æ± 
   - åŠæ—¶é‡Šæ”¾èµ„æº
   - é¿å…å†…å­˜æ³„æ¼

4. **å¹¶å‘æ§åˆ¶**
   - åˆç†æ§åˆ¶å¹¶å‘æ•°
   - é¿å…è¿‡åº¦å¹¶å‘
   - ä½¿ç”¨é€‚å½“çš„åŒæ­¥æœºåˆ¶

é€šè¿‡è¿™äº›ä¼˜åŒ–æŠ€æœ¯ï¼Œå¯ä»¥æ˜¾è‘—æå‡Goåº”ç”¨çš„æ€§èƒ½å’Œç¨³å®šæ€§ã€‚go
package tools

import (
	"context"
	"fmt"
	"net/http"
	_ "net/http/pprof"
	"os"
	"runtime"
	"runtime/pprof"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/sirupsen/logrus"
)

// ProfileConfig æ€§èƒ½åˆ†æé…ç½®
type ProfileConfig struct {
	Enabled    bool   `json:"enabled"`
	Port       string `json:"port"`
	CPUProfile string `json:"cpu_profile"`
	MemProfile string `json:"mem_profile"`
}

// ProfileManager æ€§èƒ½åˆ†æç®¡ç†å™¨
type ProfileManager struct {
	config ProfileConfig
	server *http.Server
}

// NewProfileManager åˆ›å»ºæ€§èƒ½åˆ†æç®¡ç†å™¨
func NewProfileManager(config ProfileConfig) *ProfileManager {
	return &ProfileManager{
		config: config,
	}
}

// Start å¯åŠ¨æ€§èƒ½åˆ†ææœåŠ¡
func (pm *ProfileManager) Start() error {
	if !pm.config.Enabled {
		return nil
	}

	// å¯åŠ¨pprofæœåŠ¡
	mux := http.NewServeMux()
	mux.HandleFunc("/debug/pprof/", http.HandlerFunc(pprof.Index))
	mux.HandleFunc("/debug/pprof/cmdline", http.HandlerFunc(pprof.Cmdline))
	mux.HandleFunc("/debug/pprof/profile", http.HandlerFunc(pprof.Profile))
	mux.HandleFunc("/debug/pprof/symbol", http.HandlerFunc(pprof.Symbol))
	mux.HandleFunc("/debug/pprof/trace", http.HandlerFunc(pprof.Trace))

	pm.server = &http.Server{
		Addr:    ":" + pm.config.Port,
		Handler: mux,
	}

	go func() {
		logrus.Infof("æ€§èƒ½åˆ†ææœåŠ¡å¯åŠ¨åœ¨ç«¯å£ %s", pm.config.Port)
		if err := pm.server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
			logrus.Errorf("æ€§èƒ½åˆ†ææœåŠ¡å¯åŠ¨å¤±è´¥: %v", err)
		}
	}()

	return nil
}

// Stop åœæ­¢æ€§èƒ½åˆ†ææœåŠ¡
func (pm *ProfileManager) Stop() error {
	if pm.server == nil {
		return nil
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	return pm.server.Shutdown(ctx)
}

// StartCPUProfile å¼€å§‹CPUæ€§èƒ½åˆ†æ
func (pm *ProfileManager) StartCPUProfile() error {
	if pm.config.CPUProfile == "" {
		return fmt.Errorf("CPU profileæ–‡ä»¶è·¯å¾„æœªé…ç½®")
	}

	f, err := os.Create(pm.config.CPUProfile)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºCPU profileæ–‡ä»¶å¤±è´¥: %v", err)
	}

	if err := pprof.StartCPUProfile(f); err != nil {
		f.Close()
		return fmt.Errorf("å¯åŠ¨CPU profileå¤±è´¥: %v", err)
	}

	logrus.Infof("CPUæ€§èƒ½åˆ†æå·²å¯åŠ¨ï¼Œè¾“å‡ºæ–‡ä»¶: %s", pm.config.CPUProfile)
	return nil
}

// StopCPUProfile åœæ­¢CPUæ€§èƒ½åˆ†æ
func (pm *ProfileManager) StopCPUProfile() {
	pprof.StopCPUProfile()
	logrus.Info("CPUæ€§èƒ½åˆ†æå·²åœæ­¢")
}

// WriteMemProfile å†™å…¥å†…å­˜æ€§èƒ½åˆ†æ
func (pm *ProfileManager) WriteMemProfile() error {
	if pm.config.MemProfile == "" {
		return fmt.Errorf("å†…å­˜profileæ–‡ä»¶è·¯å¾„æœªé…ç½®")
	}

	f, err := os.Create(pm.config.MemProfile)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºå†…å­˜profileæ–‡ä»¶å¤±è´¥: %v", err)
	}
	defer f.Close()

	runtime.GC() // å¼ºåˆ¶åƒåœ¾å›æ”¶
	if err := pprof.WriteHeapProfile(f); err != nil {
		return fmt.Errorf("å†™å…¥å†…å­˜profileå¤±è´¥: %v", err)
	}

	logrus.Infof("å†…å­˜æ€§èƒ½åˆ†æå·²ä¿å­˜åˆ°: %s", pm.config.MemProfile)
	return nil
}

// MemoryStats å†…å­˜ç»Ÿè®¡ä¿¡æ¯
type MemoryStats struct {
	Alloc        uint64 `json:"alloc"`         // å½“å‰åˆ†é…çš„å†…å­˜
	TotalAlloc   uint64 `json:"total_alloc"`   // æ€»åˆ†é…çš„å†…å­˜
	Sys          uint64 `json:"sys"`           // ç³»ç»Ÿå†…å­˜
	Lookups      uint64 `json:"lookups"`       // æŸ¥æ‰¾æ¬¡æ•°
	Mallocs      uint64 `json:"mallocs"`       // åˆ†é…æ¬¡æ•°
	Frees        uint64 `json:"frees"`         // é‡Šæ”¾æ¬¡æ•°
	HeapAlloc    uint64 `json:"heap_alloc"`    // å †åˆ†é…
	HeapSys      uint64 `json:"heap_sys"`      // å †ç³»ç»Ÿå†…å­˜
	HeapIdle     uint64 `json:"heap_idle"`     // å †ç©ºé—²å†…å­˜
	HeapInuse    uint64 `json:"heap_inuse"`    // å †ä½¿ç”¨å†…å­˜
	HeapReleased uint64 `json:"heap_released"` // å †é‡Šæ”¾å†…å­˜
	HeapObjects  uint64 `json:"heap_objects"`  // å †å¯¹è±¡æ•°
	StackInuse   uint64 `json:"stack_inuse"`   // æ ˆä½¿ç”¨å†…å­˜
	StackSys     uint64 `json:"stack_sys"`     // æ ˆç³»ç»Ÿå†…å­˜
	MSpanInuse   uint64 `json:"mspan_inuse"`   // MSpanä½¿ç”¨å†…å­˜
	MSpanSys     uint64 `json:"mspan_sys"`     // MSpanç³»ç»Ÿå†…å­˜
	MCacheInuse  uint64 `json:"mcache_inuse"`  // MCacheä½¿ç”¨å†…å­˜
	MCacheSys    uint64 `json:"mcache_sys"`    // MCacheç³»ç»Ÿå†…å­˜
	GCSys        uint64 `json:"gc_sys"`        // GCç³»ç»Ÿå†…å­˜
	OtherSys     uint64 `json:"other_sys"`     // å…¶ä»–ç³»ç»Ÿå†…å­˜
	NextGC       uint64 `json:"next_gc"`       // ä¸‹æ¬¡GCé˜ˆå€¼
	LastGC       uint64 `json:"last_gc"`       // ä¸Šæ¬¡GCæ—¶é—´
	NumGC        uint32 `json:"num_gc"`        // GCæ¬¡æ•°
	NumForcedGC  uint32 `json:"num_forced_gc"` // å¼ºåˆ¶GCæ¬¡æ•°
	GCCPUFraction float64 `json:"gc_cpu_fraction"` // GC CPUå æ¯”
}

// GetMemoryStats è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯
func GetMemoryStats() MemoryStats {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)

	return MemoryStats{
		Alloc:         m.Alloc,
		TotalAlloc:    m.TotalAlloc,
		Sys:           m.Sys,
		Lookups:       m.Lookups,
		Mallocs:       m.Mallocs,
		Frees:         m.Frees,
		HeapAlloc:     m.HeapAlloc,
		HeapSys:       m.HeapSys,
		HeapIdle:      m.HeapIdle,
		HeapInuse:     m.HeapInuse,
		HeapReleased:  m.HeapReleased,
		HeapObjects:   m.HeapObjects,
		StackInuse:    m.StackInuse,
		StackSys:      m.StackSys,
		MSpanInuse:    m.MSpanInuse,
		MSpanSys:      m.MSpanSys,
		MCacheInuse:   m.MCacheInuse,
		MCacheSys:     m.MCacheSys,
		GCSys:         m.GCSys,
		OtherSys:      m.OtherSys,
		NextGC:        m.NextGC,
		LastGC:        m.LastGC,
		NumGC:         m.NumGC,
		NumForcedGC:   m.NumForcedGC,
		GCCPUFraction: m.GCCPUFraction,
	}
}

// PerformanceMiddleware æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶
func PerformanceMiddleware() gin.HandlerFunc {
	return gin.HandlerFunc(func(c *gin.Context) {
		start := time.Now()
		path := c.Request.URL.Path
		method := c.Request.Method

		// å¤„ç†è¯·æ±‚
		c.Next()

		// è®¡ç®—å¤„ç†æ—¶é—´
		duration := time.Since(start)
		status := c.Writer.Status()

		// è®°å½•æ€§èƒ½æŒ‡æ ‡
		logrus.WithFields(logrus.Fields{
			"method":   method,
			"path":     path,
			"status":   status,
			"duration": duration.Milliseconds(),
			"size":     c.Writer.Size(),
		}).Info("è¯·æ±‚å¤„ç†å®Œæˆ")

		// æ…¢è¯·æ±‚å‘Šè­¦
		if duration > 1*time.Second {
			logrus.WithFields(logrus.Fields{
				"method":   method,
				"path":     path,
				"duration": duration.Milliseconds(),
			}).Warn("æ…¢è¯·æ±‚æ£€æµ‹")
		}
	})
}

// BenchmarkTest åŸºå‡†æµ‹è¯•
type BenchmarkTest struct {
	Name     string
	Function func() error
	Runs     int
}

// RunBenchmark è¿è¡ŒåŸºå‡†æµ‹è¯•
func RunBenchmark(tests []BenchmarkTest) {
	for _, test := range tests {
		logrus.Infof("å¼€å§‹åŸºå‡†æµ‹è¯•: %s", test.Name)
		
		start := time.Now()
		var totalDuration time.Duration
		var errors int

		for i := 0; i < test.Runs; i++ {
			runStart := time.Now()
			if err := test.Function(); err != nil {
				errors++
				logrus.Errorf("åŸºå‡†æµ‹è¯•é”™è¯¯: %v", err)
			}
			totalDuration += time.Since(runStart)
		}

		totalTime := time.Since(start)
		avgDuration := totalDuration / time.Duration(test.Runs)
		successRate := float64(test.Runs-errors) / float64(test.Runs) * 100

		logrus.WithFields(logrus.Fields{
			"test":         test.Name,
			"runs":         test.Runs,
			"total_time":   totalTime.Milliseconds(),
			"avg_duration": avgDuration.Milliseconds(),
			"success_rate": successRate,
			"errors":       errors,
		}).Info("åŸºå‡†æµ‹è¯•å®Œæˆ")
	}
}
```

## 11.2 ä»£ç ä¼˜åŒ–

### å†…å­˜ä¼˜åŒ–

**æ–‡ä»¶è·¯å¾„ï¼š** `optimizations/memory.go`

```go
package optimizations

import (
	"sync"
	"unsafe"
)

// ObjectPool å¯¹è±¡æ± 
type ObjectPool struct {
	pool sync.Pool
	new  func() interface{}
}

// NewObjectPool åˆ›å»ºå¯¹è±¡æ± 
func NewObjectPool(newFunc func() interface{}) *ObjectPool {
	return &ObjectPool{
		pool: sync.Pool{
			New: newFunc,
		},
		new: newFunc,
	}
}

// Get è·å–å¯¹è±¡
func (p *ObjectPool) Get() interface{} {
	return p.pool.Get()
}

// Put å½’è¿˜å¯¹è±¡
func (p *ObjectPool) Put(obj interface{}) {
	p.pool.Put(obj)
}

// StringPool å­—ç¬¦ä¸²æ± 
var StringPool = NewObjectPool(func() interface{} {
	return make([]byte, 0, 1024)
})

// SlicePool åˆ‡ç‰‡æ± 
var SlicePool = NewObjectPool(func() interface{} {
	return make([]interface{}, 0, 100)
})

// MapPool Mapæ± 
var MapPool = NewObjectPool(func() interface{} {
	return make(map[string]interface{}, 100)
})

// BytesToString é›¶æ‹·è´å­—èŠ‚è½¬å­—ç¬¦ä¸²
func BytesToString(b []byte) string {
	return *(*string)(unsafe.Pointer(&b))
}

// StringToBytes é›¶æ‹·è´å­—ç¬¦ä¸²è½¬å­—èŠ‚
func StringToBytes(s string) []byte {
	return *(*[]byte)(unsafe.Pointer(
		&struct {
			string
			Cap int
		}{s, len(s)},
	))
}

// PreallocatedSlice é¢„åˆ†é…åˆ‡ç‰‡
type PreallocatedSlice struct {
	data []interface{}
	len  int
	cap  int
}

// NewPreallocatedSlice åˆ›å»ºé¢„åˆ†é…åˆ‡ç‰‡
func NewPreallocatedSlice(capacity int) *PreallocatedSlice {
	return &PreallocatedSlice{
		data: make([]interface{}, 0, capacity),
		cap:  capacity,
	}
}

// Append æ·»åŠ å…ƒç´ 
func (ps *PreallocatedSlice) Append(item interface{}) {
	if ps.len < ps.cap {
		ps.data = append(ps.data, item)
		ps.len++
	}
}

// Reset é‡ç½®åˆ‡ç‰‡
func (ps *PreallocatedSlice) Reset() {
	ps.data = ps.data[:0]
	ps.len = 0
}

// Get è·å–å…ƒç´ 
func (ps *PreallocatedSlice) Get(index int) interface{} {
	if index < ps.len {
		return ps.data[index]
	}
	return nil
}

// Len è·å–é•¿åº¦
func (ps *PreallocatedSlice) Len() int {
	return ps.len
}

// MemoryOptimizedStudent å†…å­˜ä¼˜åŒ–çš„å­¦ç”Ÿç»“æ„
type MemoryOptimizedStudent struct {
	ID       uint32 // ä½¿ç”¨uint32è€Œä¸æ˜¯uint64
	Name     string
	Age      uint8  // ä½¿ç”¨uint8è€Œä¸æ˜¯int
	Gender   bool   // ä½¿ç”¨boolè€Œä¸æ˜¯string
	Email    string
	Phone    string
	Address  string
	Grade    uint8
	Class    uint8
	Status   uint8
	// ä½¿ç”¨ä½å­—æ®µå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–
}

// Size è®¡ç®—ç»“æ„ä½“å¤§å°
func (s *MemoryOptimizedStudent) Size() uintptr {
	return unsafe.Sizeof(*s)
}

// CompactStudent ç´§å‡‘çš„å­¦ç”Ÿç»“æ„ï¼ˆä½¿ç”¨ä½å­—æ®µï¼‰
type CompactStudent struct {
	ID      uint32
	Name    string
	Email   string
	Phone   string
	Address string
	// å°†å¤šä¸ªå°å­—æ®µæ‰“åŒ…åˆ°ä¸€ä¸ªuint32ä¸­
	Packed uint32 // Age(8) + Gender(1) + Grade(8) + Class(8) + Status(7)
}

// SetAge è®¾ç½®å¹´é¾„
func (cs *CompactStudent) SetAge(age uint8) {
	cs.Packed = (cs.Packed &^ 0xFF) | uint32(age)
}

// GetAge è·å–å¹´é¾„
func (cs *CompactStudent) GetAge() uint8 {
	return uint8(cs.Packed & 0xFF)
}

// SetGender è®¾ç½®æ€§åˆ«
func (cs *CompactStudent) SetGender(isMale bool) {
	if isMale {
		cs.Packed |= 1 << 8
	} else {
		cs.Packed &^= 1 << 8
	}
}

// GetGender è·å–æ€§åˆ«
func (cs *CompactStudent) GetGender() bool {
	return (cs.Packed>>8)&1 == 1
}

// SetGrade è®¾ç½®å¹´çº§
func (cs *CompactStudent) SetGrade(grade uint8) {
	cs.Packed = (cs.Packed &^ (0xFF << 9)) | (uint32(grade) << 9)
}

// GetGrade è·å–å¹´çº§
func (cs *CompactStudent) GetGrade() uint8 {
	return uint8((cs.Packed >> 9) & 0xFF)
}

// SetClass è®¾ç½®ç­çº§
func (cs *CompactStudent) SetClass(class uint8) {
	cs.Packed = (cs.Packed &^ (0xFF << 17)) | (uint32(class) << 17)
}

// GetClass è·å–ç­çº§
func (cs *CompactStudent) GetClass() uint8 {
	return uint8((cs.Packed >> 17) & 0xFF)
}

// SetStatus è®¾ç½®çŠ¶æ€
func (cs *CompactStudent) SetStatus(status uint8) {
	cs.Packed = (cs.Packed &^ (0x7F << 25)) | (uint32(status&0x7F) << 25)
}

// GetStatus è·å–çŠ¶æ€
func (cs *CompactStudent) GetStatus() uint8 {
	return uint8((cs.Packed >> 25) & 0x7F)
}
```

### å¹¶å‘ä¼˜åŒ–

**æ–‡ä»¶è·¯å¾„ï¼š** `optimizations/concurrency.go`

```go
package optimizations

import (
	"context"
	"runtime"
	"sync"
	"time"
)

// WorkerPool å·¥ä½œæ± 
type WorkerPool struct {
	workerCount int
	jobQueue    chan Job
	workers     []*Worker
	wg          sync.WaitGroup
	ctx         context.Context
	cancel      context.CancelFunc
}

// Job å·¥ä½œä»»åŠ¡
type Job interface {
	Execute() error
}

// Worker å·¥ä½œè€…
type Worker struct {
	id       int
	jobQueue chan Job
	quit     chan bool
}

// NewWorkerPool åˆ›å»ºå·¥ä½œæ± 
func NewWorkerPool(workerCount, queueSize int) *WorkerPool {
	ctx, cancel := context.WithCancel(context.Background())
	return &WorkerPool{
		workerCount: workerCount,
		jobQueue:    make(chan Job, queueSize),
		workers:     make([]*Worker, workerCount),
		ctx:         ctx,
		cancel:      cancel,
	}
}

// Start å¯åŠ¨å·¥ä½œæ± 
func (wp *WorkerPool) Start() {
	for i := 0; i < wp.workerCount; i++ {
		worker := &Worker{
			id:       i,
			jobQueue: wp.jobQueue,
			quit:     make(chan bool),
		}
		wp.workers[i] = worker
		wp.wg.Add(1)
		go wp.runWorker(worker)
	}
}

// Stop åœæ­¢å·¥ä½œæ± 
func (wp *WorkerPool) Stop() {
	wp.cancel()
	close(wp.jobQueue)
	wp.wg.Wait()
}

// Submit æäº¤ä»»åŠ¡
func (wp *WorkerPool) Submit(job Job) bool {
	select {
	case wp.jobQueue <- job:
		return true
	case <-wp.ctx.Done():
		return false
	default:
		return false
	}
}

// runWorker è¿è¡Œå·¥ä½œè€…
func (wp *WorkerPool) runWorker(worker *Worker) {
	defer wp.wg.Done()
	for {
		select {
		case job := <-worker.jobQueue:
			if job != nil {
				job.Execute()
			}
		case <-wp.ctx.Done():
			return
		}
	}
}

// ConcurrentMap å¹¶å‘å®‰å…¨çš„Map
type ConcurrentMap struct {
	shards []*MapShard
	count  int
}

// MapShard Mapåˆ†ç‰‡
type MapShard struct {
	mu    sync.RWMutex
	items map[string]interface{}
}

// NewConcurrentMap åˆ›å»ºå¹¶å‘Map
func NewConcurrentMap(shardCount int) *ConcurrentMap {
	if shardCount <= 0 {
		shardCount = runtime.NumCPU()
	}
	
	cm := &ConcurrentMap{
		shards: make([]*MapShard, shardCount),
		count:  shardCount,
	}
	
	for i := 0; i < shardCount; i++ {
		cm.shards[i] = &MapShard{
			items: make(map[string]interface{}),
		}
	}
	
	return cm
}

// getShard è·å–åˆ†ç‰‡
func (cm *ConcurrentMap) getShard(key string) *MapShard {
	hash := fnv32(key)
	return cm.shards[hash%uint32(cm.count)]
}

// Set è®¾ç½®å€¼
func (cm *ConcurrentMap) Set(key string, value interface{}) {
	shard := cm.getShard(key)
	shard.mu.Lock()
	shard.items[key] = value
	shard.mu.Unlock()
}

// Get è·å–å€¼
func (cm *ConcurrentMap) Get(key string) (interface{}, bool) {
	shard := cm.getShard(key)
	shard.mu.RLock()
	value, ok := shard.items[key]
	shard.mu.RUnlock()
	return value, ok
}

// Delete åˆ é™¤å€¼
func (cm *ConcurrentMap) Delete(key string) {
	shard := cm.getShard(key)
	shard.mu.Lock()
	delete(shard.items, key)
	shard.mu.Unlock()
}

// Keys è·å–æ‰€æœ‰é”®
func (cm *ConcurrentMap) Keys() []string {
	var keys []string
	for _, shard := range cm.shards {
		shard.mu.RLock()
		for key := range shard.items {
			keys = append(keys, key)
		}
		shard.mu.RUnlock()
	}
	return keys
}

// fnv32 FNV-1a 32ä½å“ˆå¸Œå‡½æ•°
func fnv32(key string) uint32 {
	hash := uint32(2166136261)
	const prime32 = uint32(16777619)
	for i := 0; i < len(key); i++ {
		hash ^= uint32(key[i])
		hash *= prime32
	}
	return hash
}

// RateLimiter é™æµå™¨
type RateLimiter struct {
	rate     int
	burst    int
	tokens   int
	lastTime time.Time
	mu       sync.Mutex
}

// NewRateLimiter åˆ›å»ºé™æµå™¨
func NewRateLimiter(rate, burst int) *RateLimiter {
	return &RateLimiter{
		rate:     rate,
		burst:    burst,
		tokens:   burst,
		lastTime: time.Now(),
	}
}

// Allow æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚
func (rl *RateLimiter) Allow() bool {
	rl.mu.Lock()
	defer rl.mu.Unlock()
	
	now := time.Now()
	elapsed := now.Sub(rl.lastTime)
	rl.lastTime = now
	
	// æ·»åŠ ä»¤ç‰Œ
	tokensToAdd := int(elapsed.Seconds() * float64(rl.rate))
	rl.tokens += tokensToAdd
	if rl.tokens > rl.burst {
		rl.tokens = rl.burst
	}
	
	// æ¶ˆè´¹ä»¤ç‰Œ
	if rl.tokens > 0 {
		rl.tokens--
		return true
	}
	
	return false
}

// CircuitBreaker ç†”æ–­å™¨
type CircuitBreaker struct {
	maxFailures  int
	resetTimeout time.Duration
	state        CircuitState
	failures     int
	lastFailTime time.Time
	mu           sync.RWMutex
}

// CircuitState ç†”æ–­å™¨çŠ¶æ€
type CircuitState int

const (
	StateClosed CircuitState = iota
	StateOpen
	StateHalfOpen
)

// NewCircuitBreaker åˆ›å»ºç†”æ–­å™¨
func NewCircuitBreaker(maxFailures int, resetTimeout time.Duration) *CircuitBreaker {
	return &CircuitBreaker{
		maxFailures:  maxFailures,
		resetTimeout: resetTimeout,
		state:        StateClosed,
	}
}

// Call æ‰§è¡Œè°ƒç”¨
func (cb *CircuitBreaker) Call(fn func() error) error {
	if !cb.allowRequest() {
		return ErrCircuitOpen
	}
	
	err := fn()
	cb.recordResult(err == nil)
	return err
}

// allowRequest æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚
func (cb *CircuitBreaker) allowRequest() bool {
	cb.mu.RLock()
	defer cb.mu.RUnlock()
	
	switch cb.state {
	case StateClosed:
		return true
	case StateOpen:
		return time.Since(cb.lastFailTime) > cb.resetTimeout
	case StateHalfOpen:
		return true
	default:
		return false
	}
}

// recordResult è®°å½•ç»“æœ
func (cb *CircuitBreaker) recordResult(success bool) {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	if success {
		cb.onSuccess()
	} else {
		cb.onFailure()
	}
}

// onSuccess æˆåŠŸå¤„ç†
func (cb *CircuitBreaker) onSuccess() {
	cb.failures = 0
	if cb.state == StateHalfOpen {
		cb.state = StateClosed
	}
}

// onFailure å¤±è´¥å¤„ç†
func (cb *CircuitBreaker) onFailure() {
	cb.failures++
	cb.lastFailTime = time.Now()
	
	if cb.failures >= cb.maxFailures {
		cb.state = StateOpen
	} else if cb.state == StateHalfOpen {
		cb.state = StateOpen
	}
}

// ErrCircuitOpen ç†”æ–­å™¨å¼€å¯é”™è¯¯
var ErrCircuitOpen = fmt.Errorf("circuit breaker is open")
```

## 11.3 æ•°æ®åº“ä¼˜åŒ–

### æŸ¥è¯¢ä¼˜åŒ–

**æ–‡ä»¶è·¯å¾„ï¼š** `optimizations/database.go`

```go
package optimizations

import (
	"context"
	"database/sql"
	"fmt"
	"strings"
	"time"

	"gorm.io/gorm"
	"gorm.io/gorm/logger"
)

// QueryOptimizer æŸ¥è¯¢ä¼˜åŒ–å™¨
type QueryOptimizer struct {
	db *gorm.DB
}

// NewQueryOptimizer åˆ›å»ºæŸ¥è¯¢ä¼˜åŒ–å™¨
func NewQueryOptimizer(db *gorm.DB) *QueryOptimizer {
	return &QueryOptimizer{db: db}
}

// OptimizedStudentQuery ä¼˜åŒ–çš„å­¦ç”ŸæŸ¥è¯¢
type OptimizedStudentQuery struct {
	db    *gorm.DB
	cache map[string]interface{}
}

// NewOptimizedStudentQuery åˆ›å»ºä¼˜åŒ–çš„å­¦ç”ŸæŸ¥è¯¢
func NewOptimizedStudentQuery(db *gorm.DB) *OptimizedStudentQuery {
	return &OptimizedStudentQuery{
		db:    db,
		cache: make(map[string]interface{}),
	}
}

// GetStudentsByGradeOptimized ä¼˜åŒ–çš„æŒ‰å¹´çº§æŸ¥è¯¢å­¦ç”Ÿ
func (osq *OptimizedStudentQuery) GetStudentsByGradeOptimized(grade int, limit, offset int) ([]Student, error) {
	// ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
	var students []Student
	err := osq.db.Where("grade = ? AND deleted_at IS NULL", grade).
		Select("id, name, age, gender, email, grade, class"). // åªé€‰æ‹©éœ€è¦çš„å­—æ®µ
		Order("id"). // ä½¿ç”¨ä¸»é”®æ’åºï¼Œåˆ©ç”¨èšç°‡ç´¢å¼•
		Limit(limit).
		Offset(offset).
		Find(&students).Error
	
	return students, err
}

// BatchGetStudents æ‰¹é‡è·å–å­¦ç”Ÿ
func (osq *OptimizedStudentQuery) BatchGetStudents(ids []uint) ([]Student, error) {
	if len(ids) == 0 {
		return nil, nil
	}
	
	// ä½¿ç”¨INæŸ¥è¯¢ï¼Œä½†é™åˆ¶æ‰¹æ¬¡å¤§å°
	const batchSize = 1000
	var allStudents []Student
	
	for i := 0; i < len(ids); i += batchSize {
		end := i + batchSize
		if end > len(ids) {
			end = len(ids)
		}
		
		var batchStudents []Student
		err := osq.db.Where("id IN ? AND deleted_at IS NULL", ids[i:end]).
			Find(&batchStudents).Error
		if err != nil {
			return nil, err
		}
		
		allStudents = append(allStudents, batchStudents...)
	}
	
	return allStudents, nil
}

// SearchStudentsOptimized ä¼˜åŒ–çš„å­¦ç”Ÿæœç´¢
func (osq *OptimizedStudentQuery) SearchStudentsOptimized(keyword string, limit, offset int) ([]Student, error) {
	if keyword == "" {
		return osq.GetAllStudentsOptimized(limit, offset)
	}
	
	// ä½¿ç”¨å…¨æ–‡ç´¢å¼•æœç´¢ï¼ˆå¦‚æœæ”¯æŒï¼‰
	var students []Student
	keyword = "%" + keyword + "%"
	
	// ä¼˜å…ˆæœç´¢ç²¾ç¡®åŒ¹é…
	err := osq.db.Where("(name LIKE ? OR email LIKE ? OR phone LIKE ?) AND deleted_at IS NULL", keyword, keyword, keyword).
		Select("id, name, age, gender, email, phone, grade, class").
		Order("CASE WHEN name = ? THEN 1 WHEN name LIKE ? THEN 2 ELSE 3 END, id", strings.Trim(keyword, "%"), keyword).
		Limit(limit).
		Offset(offset).
		Find(&students).Error
	
	return students, err
}

// GetAllStudentsOptimized ä¼˜åŒ–çš„è·å–æ‰€æœ‰å­¦ç”Ÿ
func (osq *OptimizedStudentQuery) GetAllStudentsOptimized(limit, offset int) ([]Student, error) {
	var students []Student
	err := osq.db.Where("deleted_at IS NULL").
		Select("id, name, age, gender, email, phone, grade, class, created_at").
		Order("id").
		Limit(limit).
		Offset(offset).
		Find(&students).Error
	
	return students, err
}

// GetStudentStatistics è·å–å­¦ç”Ÿç»Ÿè®¡ä¿¡æ¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
func (osq *OptimizedStudentQuery) GetStudentStatistics() (map[string]interface{}, error) {
	type StatResult struct {
		TotalCount   int64 `json:"total_count"`
		MaleCount    int64 `json:"male_count"`
		FemaleCount  int64 `json:"female_count"`
		AvgAge       float64 `json:"avg_age"`
		GradeCount   int64 `json:"grade_count"`
	}
	
	// ä½¿ç”¨å•ä¸ªæŸ¥è¯¢è·å–æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯
	var result StatResult
	err := osq.db.Model(&Student{}).
		Select(`
			COUNT(*) as total_count,
			SUM(CASE WHEN gender = 'male' THEN 1 ELSE 0 END) as male_count,
			SUM(CASE WHEN gender = 'female' THEN 1 ELSE 0 END) as female_count,
			AVG(age) as avg_age,
			COUNT(DISTINCT grade) as grade_count
		`).
		Where("deleted_at IS NULL").
		Scan(&result).Error
	
	if err != nil {
		return nil, err
	}
	
	return map[string]interface{}{
		"total_count":  result.TotalCount,
		"male_count":   result.MaleCount,
		"female_count": result.FemaleCount,
		"avg_age":      result.AvgAge,
		"grade_count":  result.GradeCount,
	}, nil
}

// DatabaseOptimizer æ•°æ®åº“ä¼˜åŒ–å™¨
type DatabaseOptimizer struct {
	db *gorm.DB
}

// NewDatabaseOptimizer åˆ›å»ºæ•°æ®åº“ä¼˜åŒ–å™¨
func NewDatabaseOptimizer(db *gorm.DB) *DatabaseOptimizer {
	return &DatabaseOptimizer{db: db}
}

// CreateIndexes åˆ›å»ºä¼˜åŒ–ç´¢å¼•
func (do *DatabaseOptimizer) CreateIndexes() error {
	// ä¸ºå­¦ç”Ÿè¡¨åˆ›å»ºå¤åˆç´¢å¼•
	indexes := []string{
		"CREATE INDEX IF NOT EXISTS idx_students_grade_class ON students(grade, class)",
		"CREATE INDEX IF NOT EXISTS idx_students_name ON students(name)",
		"CREATE INDEX IF NOT EXISTS idx_students_email ON students(email)",
		"CREATE INDEX IF NOT EXISTS idx_students_phone ON students(phone)",
		"CREATE INDEX IF NOT EXISTS idx_students_deleted_at ON students(deleted_at)",
		"CREATE INDEX IF NOT EXISTS idx_students_created_at ON students(created_at)",
		"CREATE INDEX IF NOT EXISTS idx_students_grade_deleted ON students(grade, deleted_at)",
		"CREATE INDEX IF NOT EXISTS idx_students_class_deleted ON students(class, deleted_at)",
	}
	
	for _, indexSQL := range indexes {
		if err := do.db.Exec(indexSQL).Error; err != nil {
			return fmt.Errorf("åˆ›å»ºç´¢å¼•å¤±è´¥: %v", err)
		}
	}
	
	return nil
}

// AnalyzeQueries åˆ†ææ…¢æŸ¥è¯¢
func (do *DatabaseOptimizer) AnalyzeQueries() error {
	// å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—
	do.db.Logger = logger.New(
		log.New(os.Stdout, "\r\n", log.LstdFlags),
		logger.Config{
			SlowThreshold: 100 * time.Millisecond, // æ…¢æŸ¥è¯¢é˜ˆå€¼
			LogLevel:      logger.Warn,
			Colorful:      true,
		},
	)
	
	return nil
}

// OptimizeTableStructure ä¼˜åŒ–è¡¨ç»“æ„
func (do *DatabaseOptimizer) OptimizeTableStructure() error {
	// åˆ†æè¡¨å¹¶ä¼˜åŒ–
	tables := []string{"students"}
	
	for _, table := range tables {
		// MySQLç‰¹å®šçš„ä¼˜åŒ–
		if err := do.db.Exec(fmt.Sprintf("ANALYZE TABLE %s", table)).Error; err != nil {
			return fmt.Errorf("åˆ†æè¡¨ %s å¤±è´¥: %v", table, err)
		}
		
		// ä¼˜åŒ–è¡¨
		if err := do.db.Exec(fmt.Sprintf("OPTIMIZE TABLE %s", table)).Error; err != nil {
			return fmt.Errorf("ä¼˜åŒ–è¡¨ %s å¤±è´¥: %v", table, err)
		}
	}
	
	return nil
}

// ConnectionPoolOptimizer è¿æ¥æ± ä¼˜åŒ–å™¨
type ConnectionPoolOptimizer struct {
	db *gorm.DB
}

// NewConnectionPoolOptimizer åˆ›å»ºè¿æ¥æ± ä¼˜åŒ–å™¨
func NewConnectionPoolOptimizer(db *gorm.DB) *ConnectionPoolOptimizer {
	return &ConnectionPoolOptimizer{db: db}
}

// OptimizeConnectionPool ä¼˜åŒ–è¿æ¥æ± 
func (cpo *ConnectionPoolOptimizer) OptimizeConnectionPool() error {
	sqlDB, err := cpo.db.DB()
	if err != nil {
		return err
	}
	
	// è®¾ç½®æœ€å¤§æ‰“å¼€è¿æ¥æ•°
	sqlDB.SetMaxOpenConns(100)
	
	// è®¾ç½®æœ€å¤§ç©ºé—²è¿æ¥æ•°
	sqlDB.SetMaxIdleConns(10)
	
	// è®¾ç½®è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´
	sqlDB.SetConnMaxLifetime(time.Hour)
	
	// è®¾ç½®è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
	sqlDB.SetConnMaxIdleTime(time.Minute * 10)
	
	return nil
}

// GetConnectionStats è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯
func (cpo *ConnectionPoolOptimizer) GetConnectionStats() (sql.DBStats, error) {
	sqlDB, err := cpo.db.DB()
	if err != nil {
		return sql.DBStats{}, err
	}
	
	return sqlDB.Stats(), nil
}

// PreparedStatementCache é¢„ç¼–è¯‘è¯­å¥ç¼“å­˜
type PreparedStatementCache struct {
	db         *gorm.DB
	statements map[string]*sql.Stmt
	mu         sync.RWMutex
}

// NewPreparedStatementCache åˆ›å»ºé¢„ç¼–è¯‘è¯­å¥ç¼“å­˜
func NewPreparedStatementCache(db *gorm.DB) *PreparedStatementCache {
	return &PreparedStatementCache{
		db:         db,
		statements: make(map[string]*sql.Stmt),
	}
}

// GetStatement è·å–é¢„ç¼–è¯‘è¯­å¥
func (psc *PreparedStatementCache) GetStatement(query string) (*sql.Stmt, error) {
	psc.mu.RLock()
	stmt, exists := psc.statements[query]
	psc.mu.RUnlock()
	
	if exists {
		return stmt, nil
	}
	
	psc.mu.Lock()
	defer psc.mu.Unlock()
	
	// åŒé‡æ£€æŸ¥
	if stmt, exists := psc.statements[query]; exists {
		return stmt, nil
	}
	
	// åˆ›å»ºé¢„ç¼–è¯‘è¯­å¥
	sqlDB, err := psc.db.DB()
	if err != nil {
		return nil, err
	}
	
	stmt, err = sqlDB.Prepare(query)
	if err != nil {
		return nil, err
	}
	
	psc.statements[query] = stmt
	return stmt, nil
}

// Close å…³é—­æ‰€æœ‰é¢„ç¼–è¯‘è¯­å¥
func (psc *PreparedStatementCache) Close() error {
	psc.mu.Lock()
	defer psc.mu.Unlock()
	
	for _, stmt := range psc.statements {
		stmt.Close()
	}
	
	psc.statements = make(map[string]*sql.Stmt)
	return nil
}
```

## 11.4 ç¼“å­˜ä¼˜åŒ–

### å¤šçº§ç¼“å­˜

**æ–‡ä»¶è·¯å¾„ï¼š** `optimizations/cache.go`

```go
package optimizations

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"
	"time"

	"github.com/go-redis/redis/v8"
)

// CacheLevel ç¼“å­˜çº§åˆ«
type CacheLevel int

const (
	L1Cache CacheLevel = iota // å†…å­˜ç¼“å­˜
	L2Cache                   // Redisç¼“å­˜
	L3Cache                   // æ•°æ®åº“
)

// MultiLevelCache å¤šçº§ç¼“å­˜
type MultiLevelCache struct {
	l1Cache *LRUCache
	l2Cache *redis.Client
	ctx     context.Context
}

// NewMultiLevelCache åˆ›å»ºå¤šçº§ç¼“å­˜
func NewMultiLevelCache(l1Size int, redisClient *redis.Client) *MultiLevelCache {
	return &MultiLevelCache{
		l1Cache: NewLRUCache(l1Size),
		l2Cache: redisClient,
		ctx:     context.Background(),
	}
}

// Get è·å–ç¼“å­˜å€¼
func (mlc *MultiLevelCache) Get(key string) (interface{}, bool) {
	// L1ç¼“å­˜æŸ¥æ‰¾
	if value, ok := mlc.l1Cache.Get(key); ok {
		return value, true
	}
	
	// L2ç¼“å­˜æŸ¥æ‰¾
	if mlc.l2Cache != nil {
		val, err := mlc.l2Cache.Get(mlc.ctx, key).Result()
		if err == nil {
			var value interface{}
			if err := json.Unmarshal([]byte(val), &value); err == nil {
				// å›å¡«L1ç¼“å­˜
				mlc.l1Cache.Set(key, value, time.Minute*5)
				return value, true
			}
		}
	}
	
	return nil, false
}

// Set è®¾ç½®ç¼“å­˜å€¼
func (mlc *MultiLevelCache) Set(key string, value interface{}, ttl time.Duration) error {
	// è®¾ç½®L1ç¼“å­˜
	mlc.l1Cache.Set(key, value, ttl)
	
	// è®¾ç½®L2ç¼“å­˜
	if mlc.l2Cache != nil {
		data, err := json.Marshal(value)
		if err != nil {
			return err
		}
		return mlc.l2Cache.Set(mlc.ctx, key, data, ttl).Err()
	}
	
	return nil
}

// Delete åˆ é™¤ç¼“å­˜å€¼
func (mlc *MultiLevelCache) Delete(key string) error {
	// åˆ é™¤L1ç¼“å­˜
	mlc.l1Cache.Delete(key)
	
	// åˆ é™¤L2ç¼“å­˜
	if mlc.l2Cache != nil {
		return mlc.l2Cache.Del(mlc.ctx, key).Err()
	}
	
	return nil
}

// LRUCache LRUç¼“å­˜å®ç°
type LRUCache struct {
	capacity int
	cache    map[string]*CacheNode
	head     *CacheNode
	tail     *CacheNode
	mu       sync.RWMutex
}

// CacheNode ç¼“å­˜èŠ‚ç‚¹
type CacheNode struct {
	key       string
	value     interface{}
	expireAt  time.Time
	prev      *CacheNode
	next      *CacheNode
}

// NewLRUCache åˆ›å»ºLRUç¼“å­˜
func NewLRUCache(capacity int) *LRUCache {
	cache := &LRUCache{
		capacity: capacity,
		cache:    make(map[string]*CacheNode),
		head:     &CacheNode{},
		tail:     &CacheNode{},
	}
	
	cache.head.next = cache.tail
	cache.tail.prev = cache.head
	
	// å¯åŠ¨æ¸…ç†è¿‡æœŸæ•°æ®çš„goroutine
	go cache.cleanupExpired()
	
	return cache
}

// Get è·å–å€¼
func (lru *LRUCache) Get(key string) (interface{}, bool) {
	lru.mu.Lock()
	defer lru.mu.Unlock()
	
	node, exists := lru.cache[key]
	if !exists {
		return nil, false
	}
	
	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(node.expireAt) {
		lru.removeNode(node)
		delete(lru.cache, key)
		return nil, false
	}
	
	// ç§»åŠ¨åˆ°å¤´éƒ¨
	lru.moveToHead(node)
	return node.value, true
}

// Set è®¾ç½®å€¼
func (lru *LRUCache) Set(key string, value interface{}, ttl time.Duration) {
	lru.mu.Lock()
	defer lru.mu.Unlock()
	
	if node, exists := lru.cache[key]; exists {
		// æ›´æ–°ç°æœ‰èŠ‚ç‚¹
		node.value = value
		node.expireAt = time.Now().Add(ttl)
		lru.moveToHead(node)
	} else {
		// åˆ›å»ºæ–°èŠ‚ç‚¹
		newNode := &CacheNode{
			key:      key,
			value:    value,
			expireAt: time.Now().Add(ttl),
		}
		
		lru.cache[key] = newNode
		lru.addToHead(newNode)
		
		// æ£€æŸ¥å®¹é‡
		if len(lru.cache) > lru.capacity {
			tail := lru.removeTail()
			delete(lru.cache, tail.key)
		}
	}
}

// Delete åˆ é™¤å€¼
func (lru *LRUCache) Delete(key string) {
	lru.mu.Lock()
	defer lru.mu.Unlock()
	
	if node, exists := lru.cache[key]; exists {
		lru.removeNode(node)
		delete(lru.cache, key)
	}
}

// addToHead æ·»åŠ åˆ°å¤´éƒ¨
func (lru *LRUCache) addToHead(node *CacheNode) {
	node.prev = lru.head
	node.next = lru.head.next
	lru.head.next.prev = node
	lru.head.next = node
}

// removeNode ç§»é™¤èŠ‚ç‚¹
func (lru *LRUCache) removeNode(node *CacheNode) {
	node.prev.next = node.next
	node.next.prev = node.prev
}

// moveToHead ç§»åŠ¨åˆ°å¤´éƒ¨
func (lru *LRUCache) moveToHead(node *CacheNode) {
	lru.removeNode(node)
	lru.addToHead(node)
}

// removeTail ç§»é™¤å°¾éƒ¨
func (lru *LRUCache) removeTail() *CacheNode {
	last := lru.tail.prev
	lru.removeNode(last)
	return last
}

// cleanupExpired æ¸…ç†è¿‡æœŸæ•°æ®
func (lru *LRUCache) cleanupExpired() {
	ticker := time.NewTicker(time.Minute)
	defer ticker.Stop()
	
	for range ticker.C {
		lru.mu.Lock()
		now := time.Now()
		expiredKeys := make([]string, 0)
		
		for key, node := range lru.cache {
			if now.After(node.expireAt) {
				expiredKeys = append(expiredKeys, key)
			}
		}
		
		for _, key := range expiredKeys {
			node := lru.cache[key]
			lru.removeNode(node)
			delete(lru.cache, key)
		}
		lru.mu.Unlock()
	}
}

// CacheManager ç¼“å­˜ç®¡ç†å™¨
type CacheManager struct {
	cache     *MultiLevelCache
	stats     *CacheStats
	mu        sync.RWMutex
}

// CacheStats ç¼“å­˜ç»Ÿè®¡
type CacheStats struct {
	Hits        int64 `json:"hits"`
	Misses      int64 `json:"misses"`
	L1Hits      int64 `json:"l1_hits"`
	L2Hits      int64 `json:"l2_hits"`
	Sets        int64 `json:"sets"`
	Deletes     int64 `json:"deletes"`
	Evictions   int64 `json:"evictions"`
}

// NewCacheManager åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
func NewCacheManager(cache *MultiLevelCache) *CacheManager {
	return &CacheManager{
		cache: cache,
		stats: &CacheStats{},
	}
}

// Get è·å–ç¼“å­˜å€¼ï¼ˆå¸¦ç»Ÿè®¡ï¼‰
func (cm *CacheManager) Get(key string) (interface{}, bool) {
	value, hit := cm.cache.Get(key)
	
	cm.mu.Lock()
	if hit {
		cm.stats.Hits++
	} else {
		cm.stats.Misses++
	}
	cm.mu.Unlock()
	
	return value, hit
}

// Set è®¾ç½®ç¼“å­˜å€¼ï¼ˆå¸¦ç»Ÿè®¡ï¼‰
func (cm *CacheManager) Set(key string, value interface{}, ttl time.Duration) error {
	err := cm.cache.Set(key, value, ttl)
	
	cm.mu.Lock()
	cm.stats.Sets++
	cm.mu.Unlock()
	
	return err
}

// Delete åˆ é™¤ç¼“å­˜å€¼ï¼ˆå¸¦ç»Ÿè®¡ï¼‰
func (cm *CacheManager) Delete(key string) error {
	err := cm.cache.Delete(key)
	
	cm.mu.Lock()
	cm.stats.Deletes++
	cm.mu.Unlock()
	
	return err
}

// GetStats è·å–ç¼“å­˜ç»Ÿè®¡
func (cm *CacheManager) GetStats() CacheStats {
	cm.mu.RLock()
	defer cm.mu.RUnlock()
	return *cm.stats
}

// GetHitRate è·å–å‘½ä¸­ç‡
func (cm *CacheManager) GetHitRate() float64 {
	cm.mu.RLock()
	defer cm.mu.RUnlock()
	
	total := cm.stats.Hits + cm.stats.Misses
	if total == 0 {
		return 0
	}
	return float64(cm.stats.Hits) / float64(total)
}

// CacheWarmer ç¼“å­˜é¢„çƒ­å™¨
type CacheWarmer struct {
	cache   *CacheManager
	db      *gorm.DB
	workers int
}

// NewCacheWarmer åˆ›å»ºç¼“å­˜é¢„çƒ­å™¨
func NewCacheWarmer(cache *CacheManager, db *gorm.DB, workers int) *CacheWarmer {
	return &CacheWarmer{
		cache:   cache,
		db:      db,
		workers: workers,
	}
}

// WarmupStudentCache é¢„çƒ­å­¦ç”Ÿç¼“å­˜
func (cw *CacheWarmer) WarmupStudentCache() error {
	// è·å–çƒ­ç‚¹æ•°æ®
	var students []Student
	err := cw.db.Where("deleted_at IS NULL").
		Order("created_at DESC").
		Limit(1000). // é¢„çƒ­æœ€è¿‘çš„1000ä¸ªå­¦ç”Ÿ
		Find(&students).Error
	if err != nil {
		return err
	}
	
	// å¹¶å‘é¢„çƒ­
	workerPool := NewWorkerPool(cw.workers, len(students))
	workerPool.Start()
	defer workerPool.Stop()
	
	for _, student := range students {
		student := student // é¿å…é—­åŒ…é—®é¢˜
		job := &CacheWarmupJob{
			cache:   cw.cache,
			student: student,
		}
		workerPool.Submit(job)
	}
	
	return nil
}

// CacheWarmupJob ç¼“å­˜é¢„çƒ­ä»»åŠ¡
type CacheWarmupJob struct {
	cache   *CacheManager
	student Student
}

// Execute æ‰§è¡Œé¢„çƒ­ä»»åŠ¡
func (cwj *CacheWarmupJob) Execute() error {
	key := fmt.Sprintf("student:%d", cwj.student.ID)
	return cwj.cache.Set(key, cwj.student, time.Hour)
}
```

## 11.5 ç½‘ç»œä¼˜åŒ–

### HTTPä¼˜åŒ–

**æ–‡ä»¶è·¯å¾„ï¼š** `optimizations/http.go`

```go
package optimizations

import (
	"compress/gzip"
	"io"
	"net/http"
	"strings"
	"sync"
	"time"

	"github.com/gin-gonic/gin"
)

// CompressionMiddleware å‹ç¼©ä¸­é—´ä»¶
func CompressionMiddleware() gin.HandlerFunc {
	return gin.HandlerFunc(func(c *gin.Context) {
		// æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ”¯æŒgzip
		if !strings.Contains(c.GetHeader("Accept-Encoding"), "gzip") {
			c.Next()
			return
		}
		
		// æ£€æŸ¥å†…å®¹ç±»å‹æ˜¯å¦éœ€è¦å‹ç¼©
		contentType := c.GetHeader("Content-Type")
		if !shouldCompress(contentType) {
			c.Next()
			return
		}
		
		// è®¾ç½®å‹ç¼©å“åº”å¤´
		c.Header("Content-Encoding", "gzip")
		c.Header("Vary", "Accept-Encoding")
		
		// åˆ›å»ºgzip writer
		gzipWriter := gzip.NewWriter(c.Writer)
		defer gzipWriter.Close()
		
		// æ›¿æ¢writer
		c.Writer = &gzipResponseWriter{
			ResponseWriter: c.Writer,
			gzipWriter:     gzipWriter,
		}
		
		c.Next()
	})
}

// shouldCompress åˆ¤æ–­æ˜¯å¦åº”è¯¥å‹ç¼©
func shouldCompress(contentType string) bool {
	compressibleTypes := []string{
		"text/",
		"application/json",
		"application/javascript",
		"application/xml",
		"image/svg+xml",
	}
	
	for _, t := range compressibleTypes {
		if strings.Contains(contentType, t) {
			return true
		}
	}
	return false
}

// gzipResponseWriter gzipå“åº”å†™å…¥å™¨
type gzipResponseWriter struct {
	gin.ResponseWriter
	gzipWriter *gzip.Writer
}

// Write å†™å…¥æ•°æ®
func (grw *gzipResponseWriter) Write(data []byte) (int, error) {
	return grw.gzipWriter.Write(data)
}

// WriteString å†™å…¥å­—ç¬¦ä¸²
func (grw *gzipResponseWriter) WriteString(s string) (int, error) {
	return grw.gzipWriter.Write([]byte(s))
}

// ConnectionPoolMiddleware è¿æ¥æ± ä¸­é—´ä»¶
func ConnectionPoolMiddleware() gin.HandlerFunc {
	return gin.HandlerFunc(func(c *gin.Context) {
		// è®¾ç½®Keep-Alive
		c.Header("Connection", "keep-alive")
		c.Header("Keep-Alive", "timeout=60, max=1000")
		
		c.Next()
	})
}

// ETagMiddleware ETagç¼“å­˜ä¸­é—´ä»¶
func ETagMiddleware() gin.HandlerFunc {
	return gin.HandlerFunc(func(c *gin.Context) {
		// åªå¯¹GETè¯·æ±‚å¯ç”¨ETag
		if c.Request.Method != "GET" {
			c.Next()
			return
		}
		
		// åˆ›å»ºETagå“åº”å†™å…¥å™¨
		etagWriter := &etagResponseWriter{
			ResponseWriter: c.Writer,
			request:        c.Request,
		}
		c.Writer = etagWriter
		
		c.Next()
		
		// å¤„ç†ETag
		etagWriter.handleETag()
	})
}

// etagResponseWriter ETagå“åº”å†™å…¥å™¨
type etagResponseWriter struct {
	gin.ResponseWriter
	request *http.Request
	body    []byte
}

// Write å†™å…¥æ•°æ®
func (erw *etagResponseWriter) Write(data []byte) (int, error) {
	erw.body = append(erw.body, data...)
	return len(data), nil
}

// handleETag å¤„ç†ETag
func (erw *etagResponseWriter) handleETag() {
	if len(erw.body) == 0 {
		return
	}
	
	// ç”ŸæˆETag
	etag := fmt.Sprintf(`"%x"`, md5.Sum(erw.body))
	
	// æ£€æŸ¥If-None-Matchå¤´
	ifNoneMatch := erw.request.Header.Get("If-None-Match")
	if ifNoneMatch == etag {
		erw.ResponseWriter.WriteHeader(http.StatusNotModified)
		return
	}
	
	// è®¾ç½®ETagå¤´å¹¶å†™å…¥å“åº”
	erw.ResponseWriter.Header().Set("ETag", etag)
	erw.ResponseWriter.Write(erw.body)
}
```